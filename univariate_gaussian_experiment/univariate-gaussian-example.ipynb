{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from collections import OrderedDict\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "# use ggplot styles for graphs\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import pickle\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# set tf logger to log level ERROR to avoid warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfk = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import probabilistic models\n",
    "from bayes_vi.models import Model\n",
    "\n",
    "# import utils\n",
    "from bayes_vi.utils.datasets import make_dataset_from_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcmc imports\n",
    "from bayes_vi.inference.mcmc import MCMC\n",
    "from bayes_vi.inference.mcmc.transition_kernels import HamiltonianMonteCarlo, NoUTurnSampler, RandomWalkMetropolis\n",
    "from bayes_vi.inference.mcmc.stepsize_adaptation_kernels import SimpleStepSizeAdaptation, DualAveragingStepSizeAdaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi imports \n",
    "from bayes_vi.inference.vi import VI\n",
    "\n",
    "from bayes_vi.inference.vi.surrogate_posteriors import ADVI, NormalizingFlow\n",
    "from bayes_vi.utils import to_ordered_dict\n",
    "from bayes_vi.inference.vi.flow_bijectors import HamiltonianFlow, AffineFlow, make_energy_fn, make_scale_fn, make_shift_fn\n",
    "from bayes_vi.utils.leapfrog_integrator import LeapfrogIntegrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - Univariate Gaussian Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMC Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling params\n",
    "NUM_CHAINS = 4\n",
    "NUM_SAMPLES = 2500\n",
    "NUM_BURNIN_STEPS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define step size adaptation\n",
    "stepsize_adaptation_kernel = DualAveragingStepSizeAdaptation(num_adaptation_steps=int(NUM_BURNIN_STEPS*0.8))\n",
    "\n",
    "kernel = NoUTurnSampler(\n",
    "    step_size=0.01, \n",
    "    max_tree_depth=5,\n",
    "    stepsize_adaptation_kernel=stepsize_adaptation_kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEPS = 5000\n",
    "SAMPLE_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam\n",
    "init_lr = {\n",
    "    'meanfield_advi': 1e-2, \n",
    "    'affine_flow': 1e-2,\n",
    "    'maf': 1e-2,\n",
    "    'cnf': 1e-3,\n",
    "    'hnf-1': 1e-3,\n",
    "    'hnf-2': 1e-3,\n",
    "    'hnf-5': 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dict = {\n",
    "    \"mean\": np.mean,\n",
    "    \"stddev\": np.std,\n",
    "    \"min\": lambda x: np.percentile(x, 0),\n",
    "    \"hdi_3%\": lambda x: np.percentile(x, 3),\n",
    "    \"mode\": lambda x: np.percentile(x, 50),\n",
    "    \"hdi_97%\": lambda x: np.percentile(x, 97),\n",
    "    \"max\": lambda x: np.percentile(x, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_flow_bijector(unconstrained_event_dims):\n",
    "    state_fn = tfk.Sequential()\n",
    "    state_fn.add(tfk.layers.Dense(128, activation=tfk.activations.tanh))\n",
    "    state_fn.add(tfk.layers.Dense(128, activation=tfk.activations.tanh))\n",
    "    state_fn.add(tfk.layers.Dense(unconstrained_event_dims))\n",
    "    state_fn.build((None, unconstrained_event_dims+1))\n",
    "    state_time_derivative_fn = lambda t, state: state_fn(tf.concat([tf.fill((state.shape[0],1), t), state], axis=-1))\n",
    "    return tfb.FFJORD(state_time_derivative_fn, \n",
    "                      ode_solve_fn=tfp.math.ode.DormandPrince(first_step_size=0.1).solve, \n",
    "                      trace_augmentation_fn=tfb.ffjord.trace_jacobian_hutchinson)\n",
    "    \n",
    "def get_hamiltonian_flow_bijector(unconstrained_event_dims, num_flows):\n",
    "    return tfb.Chain([\n",
    "        HamiltonianFlow(\n",
    "            event_dims=unconstrained_event_dims,\n",
    "            symplectic_integrator=LeapfrogIntegrator(), \n",
    "            step_sizes=0.1, \n",
    "            num_integration_steps=5,\n",
    "            hidden_layers=[128, 128]\n",
    "        ) for _ in range(num_flows)\n",
    "    ])\n",
    "\n",
    "def get_masked_autoregressive_flow_bijector(unconstrained_event_dims):\n",
    "    return tfb.MaskedAutoregressiveFlow(\n",
    "        shift_and_log_scale_fn=tfb.AutoregressiveNetwork(params=2, hidden_units=[32, 32], activation='relu')\n",
    "    )\n",
    "\n",
    "def get_affine_flow_bijector(unconstrained_event_dims):\n",
    "    return AffineFlow(unconstrained_event_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = OrderedDict(\n",
    "    loc = tfd.Normal(loc=0.1, scale=10.),\n",
    "    scale = tfd.HalfNormal(scale=10.)\n",
    ")\n",
    "\n",
    "likelihood = lambda loc, scale: tfd.Normal(\n",
    "    loc=loc, \n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(priors=priors, likelihood=likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 10\n",
    "num_datapoints = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params = {}\n",
    "datasets = {}\n",
    "\n",
    "for i in range(1, num_datasets+1):\n",
    "    dist = model.get_joint_distribution(targets=tf.ones(shape=(num_datapoints,)))\n",
    "    loc, scale, y = dist.sample().values()\n",
    "    \n",
    "    true_params['dataset_{}'.format(i)] = to_ordered_dict(\n",
    "        model.param_names, [loc.numpy(), scale.numpy()]\n",
    "    ) \n",
    "    datasets['dataset_{}'.format(i)] = make_dataset_from_df(\n",
    "        pd.DataFrame({'y': y}), target_names=['y'], format_features_as='dict'\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inferences and Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with dataset_1\n",
      "\n",
      "Start MCMC...\n",
      "Run NUTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2500' class='' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2500/2500 00:07<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 37.55s\n",
      "\n",
      "Finished MCMC! \n",
      "\n",
      "Start VI...\n",
      "Run meanfield_advi:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5000' class='' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5000/5000 00:04<00:00 avg loss: 326.177]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 5.09s\n",
      "\n",
      "computing error metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 10000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing error metrics in 68.51s\n",
      "\n",
      "\n",
      "Run affine_flow:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5000' class='' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5000/5000 00:05<00:00 avg loss: 326.165]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 5.37s\n",
      "\n",
      "computing error metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 10000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing error metrics in 61.71s\n",
      "\n",
      "\n",
      "Run maf:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5000' class='' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5000/5000 00:07<00:00 avg loss: 326.185]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 7.93s\n",
      "\n",
      "computing error metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 10000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing error metrics in 78.02s\n",
      "\n",
      "\n",
      "Run cnf:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5000' class='' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5000/5000 07:25<00:00 avg loss: 326.180]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 447.23s\n",
      "\n",
      "computing error metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 10000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing error metrics in 73.2s\n",
      "\n",
      "\n",
      "Run hnf-1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5000' class='' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5000/5000 00:30<00:00 avg loss: 352.147]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 31.08s\n",
      "\n",
      "computing error metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arviz - WARNING - Shape validation failed: input_shape: (1, 10000), minimum_shape: (chains=2, draws=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing error metrics in 36.56s\n",
      "\n",
      "\n",
      "Run hnf-2:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hnf-2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a841af60f682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Run {}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrogate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mapprox_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_lr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msurrogate_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAMPLE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished in {}s\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hnf-2'"
     ]
    }
   ],
   "source": [
    "for i, (name, dataset) in enumerate(datasets.items()):\n",
    "    print('Starting with {}\\n'.format(name))\n",
    "    features, targets = list(dataset.batch(dataset.cardinality()).take(1))[0]\n",
    "    \n",
    "    results[name]={\n",
    "        'data': {\n",
    "            'targets': targets.numpy(),\n",
    "            'true_params': true_params[name],\n",
    "        }}\n",
    "\n",
    "    ################################################################################################################################\n",
    "    \n",
    "    # MCMC\n",
    "    print('Start MCMC...')\n",
    "\n",
    "    mcmc = MCMC(model=model, dataset=dataset, transition_kernel=kernel)\n",
    "    \n",
    "    print('Run NUTS:')\n",
    "    start = time.time()\n",
    "    mcmc_result = mcmc.fit(\n",
    "        num_chains=NUM_CHAINS, \n",
    "        num_samples=NUM_SAMPLES, \n",
    "        num_burnin_steps=NUM_BURNIN_STEPS,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "    run_time = round(time.time() - start, 2)\n",
    "    print('Finished in {}s\\n'.format(run_time))\n",
    "\n",
    "    post_pred_dist = model.get_posterior_predictive_distribution(\n",
    "        posterior_samples=mcmc_result.samples,\n",
    "    )\n",
    "    posterior_predictive_samples = post_pred_dist.sample(1000)['y'].numpy()\n",
    "\n",
    "    posterior_samples = OrderedDict([(k, np.swapaxes(v.numpy(), 0, 1)) for k, v in zip(model.param_names, mcmc_result.samples)])\n",
    "    traces = {k: np.swapaxes(v.numpy(), 0, 1) if tf.rank(v) >= 2 else v for k,v in mcmc_result.trace.items()}\n",
    "    summary = az.summary(posterior_samples, round_to=2)\n",
    "    \n",
    "    mcmc_results = {\n",
    "        'posterior_samples': posterior_samples,\n",
    "        'traces': traces,\n",
    "        'posterior_predictive_samples': posterior_predictive_samples,\n",
    "        'acceptance_ratios_per_chain': mcmc_result.accept_ratios.numpy(),\n",
    "        'summary': summary,\n",
    "        'run_time': run_time\n",
    "    }\n",
    "    \n",
    "    results[name]['mcmc'] = mcmc_results\n",
    "    \n",
    "    print('Finished MCMC! \\n')\n",
    "    ################################################################################################################################\n",
    "    \n",
    "    # VI\n",
    "    unconstrained_event_dims = model.flat_unconstrained_param_event_ndims    \n",
    "    \n",
    "    surrogate_posteriors = {\n",
    "        'meanfield_advi': ADVI(model, mean_field=True), \n",
    "        'affine_flow': NormalizingFlow(model, flow_bijector=get_affine_flow_bijector(unconstrained_event_dims)),\n",
    "        'maf': NormalizingFlow(model, flow_bijector=get_masked_autoregressive_flow_bijector(unconstrained_event_dims)),\n",
    "        'cnf': NormalizingFlow(model, flow_bijector=get_continuous_flow_bijector(unconstrained_event_dims)),\n",
    "        'hnf-1': NormalizingFlow(model, flow_bijector=get_hamiltonian_flow_bijector(unconstrained_event_dims, num_flows=1), extra_ndims=unconstrained_event_dims),\n",
    "        'hnf-2': NormalizingFlow(model, flow_bijector=get_hamiltonian_flow_bijector(unconstrained_event_dims, num_flows=2), extra_ndims=unconstrained_event_dims),\n",
    "        'hnf-5': NormalizingFlow(model, flow_bijector=get_hamiltonian_flow_bijector(unconstrained_event_dims, num_flows=5), extra_ndims=unconstrained_event_dims),\n",
    "    }\n",
    "    \n",
    "    vi_results = {}\n",
    "    \n",
    "    print('Start VI...')\n",
    "    for surrogate_name, surrogate_posterior in surrogate_posteriors.items():\n",
    "    \n",
    "        vi = VI(model, dataset, surrogate_posterior)\n",
    "        \n",
    "        print('Run {}:'.format(surrogate_name))\n",
    "        start = time.time()\n",
    "        approx_posterior, losses = vi.fit(optimizer=optimizer(init_lr[surrogate_name]), num_steps=NUM_STEPS, sample_size=SAMPLE_SIZE, progress_bar=True)\n",
    "        run_time = round(time.time() - start, 2)\n",
    "        print('Finished in {}s\\n'.format(run_time))\n",
    "\n",
    "        print('computing error metrics...')\n",
    "        start = time.time()\n",
    "\n",
    "        post_pred_dist = model.get_posterior_predictive_distribution(\n",
    "            posterior_distribution=approx_posterior\n",
    "        )\n",
    "        posterior_predictive_samples = post_pred_dist.sample(1000)['y'].numpy()\n",
    "        posterior_samples = OrderedDict([(k, np.expand_dims(v.numpy(),0)) for k, v in approx_posterior.sample(10000).items()])\n",
    "        \n",
    "        summary = az.summary(posterior_samples, stat_funcs=func_dict, extend=False)\n",
    "        \n",
    "        # compute Wasserstein distance\n",
    "        flat_mcmc_samples = OrderedDict([(k,np.expand_dims(v.flatten(), 1)) for k, v in mcmc_results['posterior_samples'].items()])\n",
    "        flat_vi_samples = OrderedDict([(k,np.expand_dims(v.flatten(), 1)) for k, v in posterior_samples.items()])\n",
    "        distances = OrderedDict([(k, ot.dist(flat_mcmc_samples[k], flat_vi_samples[k])) for k in flat_vi_samples.keys()])\n",
    "        W2 = OrderedDict([(k, np.sqrt(\n",
    "            ot.sinkhorn2(\n",
    "                ot.unif(flat_mcmc_samples[k].size), \n",
    "                ot.unif(flat_vi_samples[k].size), \n",
    "                dist/dist.max(), \n",
    "                reg=1e-3\n",
    "            ))) for k, dist in distances.items()]) \n",
    "        \n",
    "        # compute absolute posterior mean difference to mcmc result\n",
    "        posterior_mean_error = OrderedDict([(k, np.abs(v.mean() - flat_mcmc_samples[k].mean())) for k, v in flat_vi_samples.items()])\n",
    "        comp_time = round(time.time() - start, 2)\n",
    "        print('Finished computing error metrics in {}s\\n\\n'.format(comp_time))\n",
    "        \n",
    "        vi_result = {\n",
    "            'losses': losses,\n",
    "            'final_loss': losses[-100:].mean(),\n",
    "            'posterior_samples': posterior_samples,\n",
    "            'posterior_predictive_samples': posterior_predictive_samples,\n",
    "            'summary': summary,\n",
    "            'W2': W2,\n",
    "            'posterior_mean_error':  posterior_mean_error,\n",
    "            'run_time': run_time,\n",
    "        }\n",
    "        vi_results[surrogate_name] = vi_result\n",
    "    print('Finished VI! \\n\\n\\n\\n')\n",
    "    results[name]['vi'] = vi_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loc_W2_mean = np.mean([v['vi']['maf']['W2']['loc'] for v in results.values()])\n",
    "scale_W2_mean = np.mean([v['vi']['maf']['W2']['scale'] for v in results.values()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./univariate_gaussian_exp_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('./filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
